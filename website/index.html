<!doctype html>
<html lang="en">
    <head>
        <title>Title</title>
        <!-- Required meta tags -->
        <meta charset="utf-8">
        <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

        <!-- Bootstrap CSS -->
        <link rel="stylesheet" href="./css/bootstrap.min.css">
        <!-- <link href="https://cdn.jsdelivr.net/npm/bootstrap@5.0.0-beta3/dist/css/bootstrap.min.css" rel="stylesheet" integrity="sha384-eOJMYsd53ii+scO/bJGFsiCZc+5NDVN2yr8+0RDqr0Ql0h+rP48ckxlpbzKgwra6" crossorigin="anonymous"> -->
        <link rel="stylesheet" href="./css/main.css">
    </head>
    <header id="intro" class="jumbo-bg">
        <div class="container pt-5">
            <div class="row text-white bg-tint pt-2">
                <div class="col-md-12">
                    <h1>Using deep learning to make new videogame levels</h1>
                    <div class="d-flex flex-row">
                        <div class="p-2">By <strong>Harman Uppal</strong></div>
                        <div class="p-2">8<sup>th</sup> April 2021</div>
                    </div>
                </div>
            </div>
        </div>
    </header>
    <body data-bs-spy="scroll" data-bs-target="#nav-side" data-bs-offset="0" tabindex="0">

        <div class="container-fluid">

            <div class="row">

                <div class="d-none d-lg-inline col-lg-2 offset-1">
                    <div id="nav-side" class="list-group-flush position-sticky nav-sticky mt-5">
                        <a class="list-group-item list-group-item-action" href="#intro">Introduction</a>
                        <a class="list-group-item list-group-item-action" href="#what-is-a-generative-adversarial-network">What is a Generative Adversarial Network?</a>
                        <a class="list-group-item list-group-item-action" href="#the-research">The research</a>
                        <a class="list-group-item list-group-item-action" href="#worked-example">Worked example</a>
                        <a class="list-group-item list-group-item-action" href="#conclusion">Conclusion</a>
                        <a class="list-group-item list-group-item-action" href="#references">References</a>
                    </div>
                </div>

                <div class="col-12 col-lg-6">
                    <div class="container">           
                        <div class="row mt-5">
                            <div class="col-md-12">

                                <!-- Introduction -->
                                <h3 class="header-colour">Introduction</h3>
    
                                <p class="text-justify">
                                    The video game industry is quickly becoming one of the largest in the entertainment sector and is estimated to reach around $200 billion by 2023.<sup><a href="#[1]">[1]</a></sup>
                                    Video games have seen a rapidly increasing uptake especially since the start of the COVID-19 restrictions<sup><a href="#[1]">[1]</a></sup> and creators are being challenged to produce
                                    and deliver quality content in shorter time frames.<sup><a href="#[2]">[2]</a></sup>
                                    Thus, techniques and tools to create content more efficiently with a similar level of quality are in high demand.
                                </p>
    
                                <p class="text-justify">
                                    One approach being explored is the use of Deep learning to generate new game levels based on existing examples.
                                    This involves the use of a deep learning technique such as a <strong>Generative Adversarial Network (GAN)</strong> to generate new images for levels to be created from. This blog will be based on a <a href="https://ieeexplore.ieee.org/document/8516539">research paper</a> in
                                    2018 titled DOOM Level Generation using Generative Adversarial Networks by Edoardo Giacomello, Pier Luca Lanzi and Daniele Loiacono.
                                    We will be looking at the work they conducted and how it works to generate a new game level with a Pytorch implementation as an example.
                                </p>

                                <p class="text-justify">
                                    But to understand the work in the paper we must first look at what a GAN is and how it works.
                                </p>
                                <!-- Introduction -->


                                <hr>
    

                                <!-- What is a GAN -->
                                <h3 id="what-is-a-generative-adversarial-network" class="header-colour mt-3">What is a Generative Adversarial Network?</h3>
    
                                <p class="text-justify">
                                    <strong>Generative Adversarial Networks</strong> are a form of <strong>deep learning artificial neural network</strong>.
                                    They work by learning the data distribution from a dataset and generating new data with similar characteristics.
                                    Two networks compete in a zero-sum game to help train the model to generate better data with one network generally
                                    referred to as a generator and the other a discriminator. The generator's job is to create the new data and the
                                    discriminator tries to determine if the new dataset is real or fake. The model improves by trying to trick the
                                    discriminator into thinking generated data is real. Initially, the results will result in obvious fake data but
                                    as the training progresses the model starts to generate more realistic results.
                                </p>
    
                                <div class="row justify-content-center my-5">
                                    <div class="col-md-8 text-center">
                                        <div class="card border-0">
                                            <img src="./images/google-gan.png" class="card-img-top" alt="google gan diagram">
                                            <div class="card-body">
                                                <small>Source: <a href="#[4]">[4]</a> - GAN example</small>
                                            </div>
                                        </div>
                                    </div>
                                </div>

                                    <!-- GAN Structure -->
                                    <h5 class="header-colour mt-3">GAN Strucutre</h5>
        
                                    <p class="text-justify">
                                        The image below shows the general layout of a GAN
                                    </p>
        
                                    <div class="row justify-content-center my-5">
                                        <div class="col-md-8 text-center">
                                            <div class="card border-0">
                                                <img src="./images/gan-diagram.png" class="card-img-top" alt="gan diagram">
                                                <div class="card-body">
                                                    <small>Diagram of GAN network with backpropagation highlighted</small>
                                                </div>
                                            </div>
                                        </div>
                                    </div>

                                    <p class="text-justify">
                                        The process of a GAN is relatively simple and is as follows:                                           
                                    </p>

                                    <ul class="text-justify">
                                        <li>First, a random input is used as a starting point for the generator and is usually just some uniform noise,
                                            think of it as a lump of clay ready to be moulded. The noise is passed to the generator which produced a sample.</li>
                                        <li>A sample is also taken from the real images and both are fed into the discriminator.</li>
                                        <li>The output of the discriminator is then passed to the loss functions for both and calculated</li>
                                        <li>Through backpropagation, signals are then sent to the generator and discriminator to update their weights accordingly</li>
                                    </ul>

                                    <p class="text-justify">
                                        During the training phase either the discriminator or generator is paused whilst the other network trains to stop avoid issues with training loops.
                                    </p>
                                    <!-- GAN Structure -->

                                    <!-- Loss Funtion -->
                                    <h5 class="header-colour">Loss Function</h5>

                                    <p class="text-justify">
                                        A GAN is essentially trying to replicate a probability distribution; thus, their loss functions usually reflect the distance between the
                                        distribution of generated and real data.
                                    </p>
                                    <!-- Loss Funtion -->

                                    <!-- Examples -->
                                    <h5 class="header-colour">Examples</h5>
                                    <p class="text-justify">
                                        GANs have generally been used to generate new images based on a dataset of other images.
                                        The image below shows a GAN that used images of celebrities to generate new images of people that look very realistic.
                                    </p>
        
                                    <div class="row justify-content-center my-5">
                                        <div class="col-md-8 text-center">
                                            <div class="card border-0">
                                                <img src="./images/celeb-gan.png" class="card-img-top" alt="celeb gan">
                                                <div class="card-body">
                                                    <small>Source: <a href="#[3]">[3]</a> - Images of faces generated by a GAN trained of celebrity faces. </small>
                                                </div>
                                            </div>
                                        </div>
                                    </div>
                                    <!-- Examples -->
                                <!-- What is a GAN? -->


                                <hr>


                                <!-- The Research -->
                                <h3 id="the-research" class="header-colour mt-3">The research</h3>

                                <p class="text-justify">
                                    The next question to ask is how a GAN can be used to make new video game levels? Well, the research paper studied uses a GAN to generate new greyscale maps
                                    for a new level based on previous levels made by humans. Each level was extracted as a series of map images from WAD files which contain all information relating to a game level.
                                    These maps showed features such as walls, floor elevation, pickup items, trigger zones for events etc. The image below shows what these images looked like.
                                    The maps of choice were from the popular 1993 first-person shooter, Doom.
                                </p>

                                <div class="row justify-content-center my-5">
                                    <div class="col-md-8 text-center">
                                        <div class="card border-0">
                                            <img src="./images/paper-inputs.png" class="card-img-top" alt="paper inputs">
                                            <div class="card-body">
                                                <small>Source: <a href="#[3]">[3]</a> - From left to right: the FloorMap, HeightMap, ThingsMap, and WallMap. </small>
                                            </div>
                                        </div>
                                    </div>
                                </div>

                                <p class="text-justify">
                                    The way a game or tool would generate levels from these maps would be to use these images as a mask whilst apply procedural generation to create the content.
                                    Being able to generate a new level layout like this would save hours of development time and would reduce the workload of developers to simply fixing any errors and applying finishing touches.
                                </p>

                                    <!-- The method -->
                                    <h5 class="header-colour">The method</h5>

                                    <p class="text-justify">
                                        In the paper, the researchers tested two different methods of using GANs to generate these files. These were an unconditional and condition network.
                                        The primary difference between the two was the conditional network’s generator was fed additional class information about each level.
                                        They used a specific variant of GAN called the Wasserstein GAN with Gradient Penalty as it showed more stable results.
                                        They also replaced the tanh activation function with a sigmoid function on the output layer as it was more suitable for greyscale images.
                                    </p>

                                        <h6 class="header-colour">Wasserstein GAN with Gradient Penalty (WGAN-GP)</h6>

                                        <p class="text-justify">
                                            (WGAN-GP) stuff
                                        </p>

                                        <h6 class="header-colour">Architecture used</h6>

                                        <p class="text-justify">
                                            To train the network they first extracted the images from 1000 WAD files as well as metadata for each level.
                                            The images, metadata (for the conditional network) and Gaussian noise were fed into the generator which generated 6 new images.
                                            The discriminator was fed either a generated or real image and trained to distinguish between the two.
                                            The image below shows an outline of the model architecture they used:
                                        </p>

                                        <div class="row justify-content-center my-3">
                                            <div class="col-md-8 text-center">
                                                <div class="card border-0">
                                                    <div class="card-body">
                                                        <div>
                                                            <img src="./images/paper-structure.png" class="h-50 w-50" alt="paper structure">
                                                        </div>
                                                        <small>Source: <a href="#[3]">[3]</a> - Architecture used to train GANs </small>
                                                    </div>
                                                </div>
                                            </div>
                                        </div>
                                    <!-- The method -->

                                    <!-- The evaluation -->
                                    <h5 class="header-colour">The evaluation</h5>

                                    <p class="text-justify">
                                        To evaluate the quality of level generated the researchers used several metrics.
                                        They do not however that it is extremely difficult to perform this sort of analysis as so the metric only gave an estimation of the quality of a level when compared to real examples.
                                        The metrics used were:
                                    </p>

                                    <ul class="text-justify">

                                        <li>
                                            <strong>The entropy of pixel distribution</strong>
                                            <p class="text-justify">
                                                By calculating the entropy of pixel distribution for both the generated and real images, the researchers were able to see how much information is encoded in each image.
                                                This allowed them to compare the images and see how much extra information or noise on average was in the generated ones.
                                                Similar entropy values are considered better results, so the aim was to get these average values as close as possible.
                                            </p>
                                        </li>

                                        <li>
                                            <strong>Average structural similarity</strong>
                                            <p class="text-justify">
                                                The Structural Similarity Index (SSIM) was used to analyse how similar the images were in terms of the luminance, the contrast, and the local structure.
                                                It was provided as a value between 0 and 1 with 1 being the same image. 
                                            </p>
                                        </li>

                                        <li>
                                            <strong>Encoding Error</strong>
                                            <p class="text-justify">
                                                This metric was used to measure the meaningfulness of pixels produced by the generator. This was a calculation of how far a pixel was from a meaningful value.
                                                For example, the pixels on a floor map are usually 0 or 255 indicating the presence of a floor or nothing.
                                                If you have a range of pixels hovering around 180 this is not very meaningful as it doesn’t indicate the presence of a floor or not.
                                                Thus, a floor map whose pixels are closely either to 255 or 0 has a better score for this metric.
                                            </p>
                                        </li>

                                        <li>
                                            <strong>Corner Error</strong>
                                            <p class="text-justify">
                                                The corner error was a measure of the structural complexity of a level. Researchers used a Harris detector to calculate the number of corners in a floor and wall map.
                                                They then compared the average corner error between the generated and real images to see if the new levels were similar in complexity to human levels.
                                            </p>
                                        </li>
                                    </ul>
                                    <!-- The evaluation -->

                                    <!-- The results -->
                                    <h5 class="header-colour">The results</h5>

                                    <p class="text-justify">
                                        After training the networks the results were promising. They were able to generate good maps that could be used to create levels.
                                        See this video which shows the images during the training process and some gameplay of a level created from the maps:
                                    </p>

                                    <div class="row justify-content-center my-5">
                                        <div class="col-md-8 text-center">
                                            <div class="card border-0">
                                                <div class="card-body">
                                                    <iframe
                                                        width="100%"
                                                        height="315"
                                                        src="https://www.youtube.com/embed/K32FZ-tjQP4"
                                                        title="YouTube video player"
                                                        frameborder="0"
                                                        allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture"
                                                        allowfullscreen></iframe>
                                                        <small>Source: <a href="https://www.youtube.com/embed/K32FZ-tjQP4">https://www.youtube.com/embed/K32FZ-tjQP4</a></small>
                                                </div>
                                            </div>
                                        </div>
                                    </div>

                                    
                                    
                                    <p class="text-justify">
                                        The outcome was that the conditional network produced better samples and showed slightly better training results compared to the unconditional one.
                                        This showed that the addition of metadata of the levels helped produce better levels closer to the human ones. The image below shows 3 levels generated by the conditional network.
                                        In each column, from the top to the bottom, are the HeightMap and the WallMap of the DOOM level used to extract the features in input to the network,
                                        the FloorMap, the HeightMap, the ThingsMap, and the WallMap of the level generated by the network.
                                    </p>

                                    <div class="row justify-content-center my-5">
                                        <div class="col-md-8 text-center">
                                            <div class="card border-0">
                                                <div class="card-body">
                                                    <div>
                                                        <img src="./images/paper-results.png" class="h-50" alt="paper structure">
                                                    </div>
                                                    <small>Source: <a href="#[3]">[3]</a> - Generated images from conditional model </small>
                                                </div>
                                            </div>
                                        </div>
                                    </div>
                                    <!-- The results -->
                                <!-- The Research -->


                                <hr>


                                <!-- Worked Example -->
                                <h3 id="worked-example" class="header-colour mt-3">Worked Example</h3>

                                <p class="text-justify">
                                    Now let us take a look at how we can generate our own doom levels using a GAN.
                                    For this, we are going to use PyTorch along with various others and build a WGAN- like the one used in the paper.
                                </p>

                                <!-- Worked Example -->

                                <!-- Conclusion -->
                                <h3 id="conclusion" class="header-colour mt-3">Conclusion</h3>

                                <!-- Conclusion -->

                                <!-- References -->
                                <h3 id="references" class="header-colour mt-3">References</h3>

                                <table>
                                    <thead>
                                        <th></th>
                                        <th></th>
                                    </thead>
                                    <tbody>
                                        <tr>
                                            <td id="[1]" class="pr-2">[1]</td>
                                            <td>T. Wijman, “The World’s 2.7 Billion Gamers Will Spend $159.3 Billion on Games in 2020;
                                                The Market Will Surpass $200 Billion by 2023,” 2020. [Online].
                                                Available: https://newzoo.com/insights/articles/newzoo-games-market-numbers-revenues-and-audience-2020-2023/. [Accessed 3 April 2021]
                                            </td>
                                        </tr>
    
                                        <tr>
                                            <td id="[2]" class="pr-2">[2]</td>
                                            <td>
                                                A. Semuels, “'Every Game You Like Is Built on the Backs of Workers.' Video Game Creators Are Burned Out and Desperate for Change,”
                                                Time, 11 June 2019. [Online]. Available: https://time.com/5603329/e3-video-game-creators-union/. [Accessed 3 April 2021].
                                            </td>
                                        </tr>
    
                                        <tr>
                                            <td id="[3]" class="pr-2">[3]</td>
                                            <td>
                                                E. Giacomello, P. L. Lanzi and D. Loiacono, “DOOM Level Generation using Generative Adversarial Networks,” in 2018 IEEE Games, Entertainment,
                                                Media Conference (GEM), Galway, Ireland, 2018. Available: https://ieeexplore.ieee.org/document/8516539/. [Accessed 23 February 2021]
                                            </td>
                                        </tr>

                                        <tr>
                                            <td id="[4]" class="pr-2">[4]</td>
                                            <td>
                                                Google, “Introduction | Generative Adversarial Networks | Google Developers,” Google, 24 05 2019. [Online].
                                                Available: https://developers.google.com/machine-learning/gan. [Accessed 10 March 2021].
                                            </td>
                                        </tr>
                                    </tbody>
                                </table>
                                <!-- References -->

                            </div>
                        </div>
            
                    </div>
                    
                </div>

            </div>

        </div>

        
        <!-- Optional JavaScript -->
        <script src="./js/popper.min.js"></script>
        <!-- <script src="https://cdnjs.cloudflare.com/ajax/libs/popper.js/1.14.7/umd/popper.min.js" integrity="sha384-UO2eT0CpHqdSJQ6hJty5KVphtPhzWj9WO1clHTMGa3JDZwrnQq4sF86dIHNDz0W1" crossorigin="anonymous"></script> -->

        <script src="./js/bootstrap.min.js"></script>
        <!-- <script src="https://cdn.jsdelivr.net/npm/bootstrap@5.0.0-beta3/dist/js/bootstrap.bundle.min.js" integrity="sha384-JEW9xMcG8R+pH31jmWH6WWP0WintQrMb4s7ZOdauHnUtxwoG2vI5DkLtS3qm9Ekf" crossorigin="anonymous"></script> -->
    </body>

    <footer class="bg-dark text-light text-center mt-3">
        <div class="container py-2">
            <span> Harman Uppal - CS4740 Deep Learning - Aston University 2021</span>
        </div>
    </footer>
</html>